{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ramakrishnanewbie/Facial_Recognition_using_CNN/blob/main/Facial_Recognition_using_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_dataset():\n",
        "    face_classifier = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
        "    def face_cropped(img):\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
        "        \n",
        "        if faces is ():\n",
        "            return None\n",
        "        for (x,y,w,h) in faces:\n",
        "            cropped_face = img[y:y+h,x:x+w]\n",
        "        return cropped_face\n",
        "    \n",
        "    cap = cv2.VideoCapture(1)\n",
        "    img_id = 0\n",
        "    \n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if face_cropped(frame) is not None:\n",
        "            img_id+=1\n",
        "            face = cv2.resize(face_cropped(frame), (200,200))\n",
        "            face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
        "            #file_name_path = \"data/\"+\"Ishwar.\"+str(img_id)+\".jpg\"\n",
        "            file_name_path = \"Images for visualization/\"+str(img_id)+'.jpg'\n",
        "            cv2.imwrite(file_name_path, face)\n",
        "            cv2.putText(face, str(img_id), (50,50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2 )\n",
        "            \n",
        "            cv2.imshow(\"Cropped_Face\", face)\n",
        "            if cv2.waitKey(1)==13 or int(img_id)==20:\n",
        "                break\n",
        "                \n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "    print(\"Collecting samples is completed !!!\")\n",
        "#generate_dataset()"
      ],
      "metadata": {
        "id": "_RtANebX9H4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def my_label(image_name):\n",
        "    name = image_name.split('.')[-3] \n",
        "    # if you have two person in your dataset\n",
        "#     if name==\"Ishwar\":\n",
        "#         return np.array([1,0])\n",
        "#     elif name==\"Manish\":\n",
        "#         return np.array([0,1])\n",
        "    \n",
        "    \n",
        "    # if you have three person in your dataset\n",
        "    if name==\"Ishwar\":\n",
        "        return np.array([1,0,0])\n",
        "    elif name==\"Manish\":\n",
        "        return np.array([0,1,0])\n",
        "    elif name==\"Bijay\":\n",
        "        return np.array([0,0,1])"
      ],
      "metadata": {
        "id": "3DfQLAYm9JBt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from random import shuffle\n",
        "from tqdm import tqdm\n",
        "def dats():\n",
        "    data = []\n",
        "    for img in tqdm(os.listdir(\"data\")):\n",
        "        path=os.path.join(\"data\",img)\n",
        "        img_data = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "        img_data = cv2.resize(img_data, (50,50))\n",
        "        data.append([np.array(img_data), my_label(img)])\n",
        "    shuffle(data)  \n",
        "    return data"
      ],
      "metadata": {
        "id": "SHh1i05x9Nve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dat=dats()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmKRK7vN9VVd",
        "outputId": "a0914f25-db79-4e53-d12b-1a8943246b61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "0it [00:00, ?it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = data[:2400]  \n",
        "test = data[2400:]\n",
        "X_train = np.array([i[0] for i in train]).reshape(-1,50,50,1)\n",
        "print(X_train.shape)\n",
        "y_train = [i[1] for i in train]\n",
        "X_test = np.array([i[0] for i in test]).reshape(-1,50,50,1)\n",
        "print(X_test.shape)\n",
        "y_test = [i[1] for i in test]\n",
        "\n",
        "import tensorflow as tf\n",
        "import tflearn\n",
        "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
        "from tflearn.layers.core import input_data, dropout, fully_connected\n",
        "from tflearn.layers.estimator import regression\n",
        "\n",
        "tf.reset_default_graph()\n",
        "convnet = input_data(shape=[50,50,1])\n",
        "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
        "# 32 filters and stride=5 so that the filter will move 5 pixel or unit at a time\n",
        "convnet = max_pool_2d(convnet, 5)\n",
        "convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
        "convnet = max_pool_2d(convnet, 5)\n",
        "convnet = conv_2d(convnet, 128, 5, activation='relu')\n",
        "convnet = max_pool_2d(convnet, 5)\n",
        "convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
        "convnet = max_pool_2d(convnet, 5)\n",
        "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
        "convnet = max_pool_2d(convnet, 5)\n",
        "\n",
        "convnet = fully_connected(convnet, 1024, activation='relu')\n",
        "convnet = dropout(convnet, 0.8)\n",
        "convnet = fully_connected(convnet, 3, activation='softmax')\n",
        "convnet = regression(convnet, optimizer='adam', learning_rate = 0.001, loss='categorical_crossentropy')\n",
        "model = tflearn.DNN(convnet, tensorboard_verbose=1)\n",
        "model.fit(X_train, y_train, n_epoch=12, validation_set=(X_test, y_test), show_metric = True, run_id=\"FRS\" )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def data_for_visualization():\n",
        "    Vdata = []\n",
        "    for img in tqdm(os.listdir(\"Images for visualization\")):\n",
        "        path = os.path.join(\"Images for visualization\", img)\n",
        "        img_num = img.split('.')[0] \n",
        "        img_data = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "        img_data = cv2.resize(img_data, (50,50))\n",
        "        Vdata.append([np.array(img_data), img_num])\n",
        "    shuffle(Vdata)\n",
        "    return Vdata\n",
        "\n",
        "    Vdata = data_for_visualization()\n",
        "\n",
        "\n",
        "    import matplotlib.pyplot as plt   # pip install matplotlib\n",
        "\n",
        "fig = plt.figure(figsize=(20,20))\n",
        "for num, data in enumerate(Vdata[:20]):\n",
        "    img_data = data[0]\n",
        "    y = fig.add_subplot(5,5, num+1)\n",
        "    image = img_data\n",
        "    data = img_data.reshape(50,50,1)\n",
        "    model_out = model.predict([data])[0]\n",
        "    \n",
        "    if np.argmax(model_out) == 0:\n",
        "        my_label = 'Ishwar'\n",
        "    elif np.argmax(model_out) == 1:\n",
        "        my_label = 'Manish'\n",
        "    else:\n",
        "        my_label = 'Bijay'\n",
        "        \n",
        "    y.imshow(image, cmap='gray')\n",
        "    plt.title(my_label)\n",
        "    \n",
        "    y.axes.get_xaxis().set_visible(False)\n",
        "    y.axes.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jqdTvi8X99v6"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMTACA/kqPC9dzkTgCe3YFC",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}